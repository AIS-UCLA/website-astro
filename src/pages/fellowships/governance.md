---
layout: ../../layouts/SimpleLayout.astro
title: AI Governance Fellowship
---


# AI Safety at UCLA Intro Fellowship: Governance Track


## Table of Contents


### Part 1: Introduction AI Safety
0. [Week 0: Overview, Ethos, and Social](#week-0-overview-ethos-and-social)
1. [Week 1: Artificial Intelligence -- How it Works and What it Can Achieve](#week-1-artificial-intelligence----how-it-works-and-what-it-can-achieve)
2. [Week 2: Catastrophic Risk from AI](#week-2-catastrophic-risk-from-ai)
3. [Week 3: AI Safety -- Goals and Challenges](#week-3-ai-safety----goals-and-challenges)


### Part 2: Introduction to AI Governance
4. [Week 4: AI Policy Levers](#week-4-ai-policy-levers)
5. [Week 5: Existing Approaches -- Corporate Governance & Open vs. Closed Source](#week-5-existing-approaches----corporate-governance--open-vs-closed-source)
6. [Week 6: New Approaches -- Compute Governance & International Approaches](#week-6-new-approaches----compute-governance--international-approaches)
7. [Week 7: Looking Ahead](#week-7-looking-ahead)


## Part 1: Introduction to AI Safety


### Week 0: Overview, Ethos, and Social


Core Content (~10 min):


1. [Fellowship Curriculum (this page)](#ai-safety-at-ucla-intro-fellowship-governance-track)


Optional Additional Content:


1. [Scope Insensitivity](https://www.lesswrong.com/posts/2ftJ38y9SRBCBsCzy/scope-insensitivity) (10 min)
2. [Biden's Executive Order on Safe, Secure, and Trustworthy AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) (10 min)


Learning Goals:


1. Get to know the fellowship and each other!
2. Get a flavor for the ethos and motivations of the fellowship
3. Optionally, get acquainted with recent AI legislation


### Week 1: Artificial Intelligence -- How it Works and What it Can Achieve


Core Content (~60 min):


1. [Andrej Karpathy - Intro to Large Language Models](https://youtu.be/zjkBMFhNj_g) (41 min)
2. [The AI Triad and What it Means for National Security Strategy by Ben Buchanan](https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Triad-Report.pdf) (intro + section 1) (20 min)


Optional Additional Content:


1. [AI, Machine Learning, and Deep Learning](https://blogs.nvidia.com/blog/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/) (10 min)
2. [Gradient Descent: How Neural Networks Learn | Chapter 2, Deep Learning](https://youtu.be/IHZwWFHWa-w) (20 min)
3. [Visualizing the Deep Learning Revolution by Richard Ngo](https://medium.com/@richardcngo/visualizing-the-deep-learning-revolution-722098eb9c5) (20 min)
4. [The Transformative Potential of AGI – and When It Might Arrive by Shane Legg and Chris Anderson](https://youtu.be/kMUdrUP-QCs?feature=shared&t=109)


Learning Goals:
1. Understand the technical backbone of modern AI models
2. Build a sense of why these technical details are relevant to AI policy, in the context of the AI triad (compute, data, and algorithms)
3. Begin to think about what risks might be posed by AI




### Week 2: Catastrophic Risk from AI


Core Content (~75 min):


1. [Preventing an AI-Related Catastrophe - 80,000 Hours](https://80000hours.org/problem-profiles/artificial-intelligence/#top) (60 min)
2. [The True Story of How GPT-2 Became Maximally Lewd](https://youtu.be/qV_rOlHjvvs?si=Y3li7yEXmQ-L7z0i) (14 min)


Optional Additional Content:


1. [Why AI Alignment Could Be Hard with Modern Deep Learning by Ajeya Cotra](https://docs.google.com/document/d/12Ly6VZ9917n84ffX5Ds-_J-ojkE5nUp-nyrnILTT48o/edit) (20 min)
2. [AI Risks that Could Lead to Catastrophe | CAIS](https://www.safe.ai/ai-risk) (25 min)
3. [What Failure Looks Like by Paul Christiano](https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like) (20 min)
4. [Auto-GPT and AI Race Acceleration by The AI Beat](https://venturebeat.com/ai/as-ai-agents-like-auto-gpt-speed-up-generative-ai-race-we-all-need-to-buckle-up-the-ai-beat/) (10 min)
5. [Existential Risk from Power-Seeking AI](https://jc.gatspress.com/pdf/existential_risk_and_powerseeking_ai.pdf) (60 min)
6. [AGI Safety from First Principles](https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view)
7. [Why Would AI Want to do Bad Things? Instrumental Convergence](https://aisafetyfundamentals.com/blog/why-might-misaligned-advanced-ai-cause-catastrophe-compilation/)


Learning Goals:
1. Understand the core arguments for existential risk from AI
2. Begin to form an idea of the different paths to reducing AI risk
3. Visualize how the techniques used to train AI directly contribute to potential bad outcomes




### Week 3: AI Safety -- Goals and Challenges


Core Content (~60 min):


1. [What is AI Alignment? – BlueDot Impact](https://aisafetyfundamentals.com/blog/what-is-ai-alignment/) (10 min)
2. [Avoiding Extreme Global Vulnerability as a Core AI Governance Problem](https://aisafetyfundamentals.com/blog/global-vulnerability/) (10 min)
3. [AI Safety Seems Hard to Measure](https://www.cold-takes.com/ai-safety-seems-hard-to-measure/) (18 min)
4. [Racing Through a Minefield: the AI deployment problem](https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/) (18 min)


Optional Additional Content:


1. [Nobody's on the Ball on AI Alignment](https://www.forourposterity.com/nobodys-on-the-ball-on-agi-alignment/) (15 min)
2. [Paradigms of AI Alignment: Components and Enablers](https://youtu.be/ZeecOKBus3Q) (34 min)
3. [Rogue AIs by the Center for AI Safety](https://www.aisafetybook.com/textbook/rogue-ai) (35 min)
4. [Managing Extreme AI Risks Amid Rapid Progress](https://arxiv.org/abs/2310.17688)
5. [The Need for Work on Technical AI Alignment by Daniel Eth](https://aisafetyfundamentals.com/blog/alignment-introduction) (25 min)
6. [AGI Ruin: A List of Lethalities](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities) (20 min)


Learning Goals:
1. Understand the term "AI alignment" -- what it means, and paths to achieving it
2. Understand the difficulties that arise when trying to align powerful AI models
3. Build a framework for the various factors that exascerbate AI risk, and how each of these could potentially be mitigated


## Part 2: Introduction to AI Governance


### Week 4: AI Policy Levers


Core Content (~60 min):


1. [The AI Triad and What It Means for National Security Strategy](https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Triad-Report.pdf) (pgs 11-15) (15 min)
2. [Primer on Safety Standards and Regulations for Industrial-Scale AI Development](https://aisafetyfundamentals.com/blog/standards-and-regulations-primer) (15 min)
3. [Historical Case Studies of Technology Governance and International Agreements](https://www.aisafetyfundamentals.com/blog/historical-case-studies/) (30 min)


Optional Additional Content:


1. [Strengthening Resilience to AI Risk: A Guide for UK Policymakers](https://cetas.turing.ac.uk/sites/default/files/2023-08/cetas-cltr_ai_risk_briefing_paper.pdf) (30 min)
2. [The Policy Playbook: Building a Systems-Oriented Approach to Technology and National Security Policy](https://cset.georgetown.edu/wp-content/uploads/The-Policy-Playbook.pdf) (45 min)
3. [The Convergence of Artificial Intelligence and the Life Sciences: Safeguarding Technology](https://www.nti.org/wp-content/uploads/2023/10/NTIBIO_AI_FINAL.pdf) (8 min)


Learning Goals:
1. Understand the direct implications of the AI triad for policy
2. Learn about existing standards for AI
3. Gain historical context on the successes and failures of past technology governance


### Week 5: Existing Approaches -- Corporate Governance & Open vs. Closed Source


Core Content (~65 min):


1. [AI Index Report 2024, Chapter 7: Policy and Governance](https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024_Chapter_7.pdf) (20 min)
2. [Open Sourcing Highly Capable Foundation Models](https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models) (45 min)


Optional Additional Content:


1. [Recent U.S. Efforts on AI Policy](https://www.cisa.gov/ai/recent-efforts) (8 min)
2. [President Biden's Executive Order on AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) (10 min)
3. [A Pro-Innovation Approach to AI Regulation](https://www.gov.uk/government/consultations/ai-regulation-a-pro-innovation-approach-policy-proposals/outcome/a-pro-innovation-approach-to-ai-regulation-government-response#executive-summary) (30 min)
4. [The Bletchley Declaration](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023) (10 min)
5. [UNESCO’s Recommendation on the Ethics of AI](https://unesdoc.unesco.org/ark:/48223/pf0000385082) (20 min)
6. [OECD AI Principles](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449) (10 min)
7. [The Case for Uncensored Models](https://erichartford.com/uncensored-models) (5 min)


Learning Goals:
1. Understand the term "corporate governance," and existing policies held by AI labs
2. Weigh the pros and cons of open-sourcing model weights
3. Understand the government's role in the regulation of AI companies


### Week 6: New Approaches -- Compute Governance & International Approaches


Core Content (~60 min):


1. [Primer on AI Chips and AI Governance](https://aisafetyfundamentals.com/blog/primer-on-ai-chips) (20 min)
2. [International Institutions for Advanced AI](https://arxiv.org/abs/2307.04699) (20 min)
3. [China’s AI Regulations and How They Get Made](https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117) (20 min)


Optional Additional Content:


1. [Computing Power and the Governance of AI](https://arxiv.org/abs/2402.08797) (45 min)
2. [Choking Off China’s Access to the Future of AI](https://www.csis.org/analysis/choking-chinas-access-future-ai) (15 min)
3. [High-Level Summary of the AI Act](https://artificialintelligenceact.eu/high-level-summary/) (10 min)
4. [Vision Statement of the US AI Safety Institute](https://www.nist.gov/system/files/documents/2024/05/21/AISI-vision-21May2024.pdf) (15 min)
5. [Model Evaluation for Extreme Risks by Toby Shevlane](https://arxiv.org/pdf/2305.15324.pdf) (35 min)
6. [Societal Adaptation to Advanced AI](https://drive.google.com/file/d/1k3uqK0dR9hVyG20-eBkR75_eYP2efolS/view?usp=sharing) (40 min)
7. [Driving U.S. Innovation in Artificial Intelligence: A Roadmap for AI Policy](https://www.politico.com/f/?id=0000018f-79a9-d62d-ab9f-f9af975d0000) (30 min)


Learning Goals:
1. Understand the term "compute governance," and why regulating compute is a promising path for mitigating AI risk
2. Survey existing international instiutions for AI, and proposals for new institutions
3. Gain context on the state of AI in China, the US's primary competitor in the field


### Week 7: Looking Ahead


Core Content (~60 min):


1. [Career Profile: AI Governance and Policy by 80000 Hours](https://80000hours.org/career-reviews/ai-policy-and-strategy/) (15 min)
2. [AI Governance Project Ideas – BlueDot Impact](https://aisafetyfundamentals.com/blog/ai-governance-project-ideas/) (10 min)
3. [12 Tentative Ideas for U.S. AI Policy by Muehlhauser](https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/) (5 min)
4. [Advice for Undergraduates](https://emergingtechpolicy.org/pathways/undergraduate-advice/) (15 min)
5. [Career Resources on US AI Policy](https://www.agisf.com/governance-blog/us-ai-policy-careers) (5 min)
6. [Career Resources on US AI Strategy Research](https://www.agisf.com/governance-blog/ai-strategy-careers) (12 min)


Optional Additional Content (~20 min):


1. [Advice for Seeking Full-Time Roles](https://emergingtechpolicy.org/pathways/full-time-roles/) (8 min)
2. [Collection of AI Governance Research Ideas](https://docs.google.com/document/d/183VGpa0iNN8bVHGwc7SOoFuib0vNuOwBvx0J9uCfPJY/edit#heading=h.s1tlf3z45y0e)
3. [So You Want to Be a Policy Entrepreneur? by Michael Mintrom](https://www.tandfonline.com/doi/full/10.1080/25741292.2019.1675989) (40 min)
4. [AI Policy Resources](https://emergingtechpolicy.org/areas/ai-policy/)
5. [10 skills you need to grow your public policy career](https://onlinecourses.bsg.ox.ac.uk/blog/public-policy-skills-you-need-to-grow-your-career/)
6. [Aptitudes for AI Governance Work](https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work)
7. [AI Safety Career Opportunities Job Board](https://jobs.80000hours.org/?refinementList%5Btags_area%5D%5B0%5D=AI%20safety%20%26%20policy&utm_source=aisf)


Learning Goals:
1. Understand what careers exist in the AI governance space, and the skills required for each
2. Browse proposals for AI governance and take note of the ones you may be interested in pursuing
3. Understand the resources available to you if you are interested in pursuing AI governance
