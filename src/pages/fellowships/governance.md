---
layout: ../../layouts/SimpleLayout.astro
title: AI Governance Fellowship
---


# AI Safety at UCLA Intro Fellowship: Governance Track


## Table of Contents


### Part 1: Introduction AI Safety
0. [Week 0: Overview, Ethos, and Social](#week-0-overview-ethos-and-social)
1. [Week 1: Artificial Intelligence -- How it Works and What it Can Achieve](#week-1-artificial-intelligence----how-it-works-and-what-it-can-achieve)
2. [Week 2: Catastrophic Risk from AI](#week-2-catastrophic-risk-from-ai)
3. [Week 3: AI Safety -- Goals and Challenges](#week-3-ai-safety----goals-and-challenges)


### Part 2: Introduction to AI Governance
4. [Week 4: AI Policy Levers](#week-4-ai-policy-levers)
5. [Week 5: Existing Approaches -- Corporate Governance & Open vs. Closed Source](#week-5-existing-approaches----corporate-governance--open-vs-closed-source)
6. [Week 6: New Approaches -- Compute Governance & International Approaches](#week-6-new-approaches----compute-governance--international-approaches)
7. [Week 7: Looking Ahead](#week-7-looking-ahead)


## Part 1: Introduction to AI Safety


### Week 0: Overview, Ethos, and Social


#### Core Content (~10 min):


1. [Fellowship Curriculum (this page)](#ai-safety-at-ucla-intro-fellowship-governance-track)


#### Optional Additional Content:


1. [Scope Insensitivity](https://www.lesswrong.com/posts/2ftJ38y9SRBCBsCzy/scope-insensitivity) (10 min)
2. [Biden's Executive Order on Safe, Secure, and Trustworthy AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) (10 min)


#### Learning Goals:


1. Get to know the fellowship and each other!
2. Get a flavor for the ethos and motivations of the fellowship
3. Optionally, get acquainted with recent AI legislation


### Week 1: Artificial Intelligence -- How it Works and What it Can Achieve


#### Core Content (~60 min):


1. [Andrej Karpathy - Intro to Large Language Models](https://youtu.be/zjkBMFhNj_g) (60 min)


#### Optional Additional Content:

AI History
1. [Visualizing the Deep Learning Revolution by Richard Ngo](https://medium.com/@richardcngo/visualizing-the-deep-learning-revolution-722098eb9c5) (20 min)
2. [Nvidia: The chip maker that became an AI superpower](https://www.bbc.co.uk/news/business-65675027) (5 min)
3. [Compute Trends Across Three Eras of Machine Learning](https://epochai.org/blog/compute-trends) (10 min)

How AI Works
1. [AI, Machine Learning, and Deep Learning](https://blogs.nvidia.com/blog/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/) (10 min)
2. [Gradient Descent: How Neural Networks Learn | Chapter 2, Deep Learning](https://youtu.be/IHZwWFHWa-w) (20 min)
3. [What is Self Supervised Learning?](https://youtu.be/sJzuNAisXHA) (5 min)

AI Futures
1. [The economic potential of generative AI: The next productivity frontier](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)
2. [Forecasting Transformative AI, Part 1: What Kind of AI?](https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/)
3. [The Transformative Potential of AGI – and When It Might Arrive by Shane Legg and Chris Anderson](https://youtu.be/kMUdrUP-QCs?feature=shared&t=109)


#### Learning Goals:
1. Understand the technical backbone of modern AI models
2. Build a sense of why these technical details are relevant to AI policy, in the context of the AI triad (compute, data, and algorithms)
3. Begin to think about what risks might be posed by AI




### Week 2: Catastrophic Risk from AI


#### Core Content (~60 min):


1. [Existential Risk from Power-Seeking AI](https://jc.gatspress.com/pdf/existential_risk_and_powerseeking_ai.pdf) (60 min)


#### Optional Additional Content:

First Principles AI Safety
1. [AGI Safety from First Principles](https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view)
2. [Why Would AI Want to do Bad Things? Instrumental Convergence](https://aisafetyfundamentals.com/blog/why-might-misaligned-advanced-ai-cause-catastrophe-compilation/)
3. [Why AI Alignment Could Be Hard with Modern Deep Learning by Ajeya Cotra](https://docs.google.com/document/d/12Ly6VZ9917n84ffX5Ds-_J-ojkE5nUp-nyrnILTT48o/edit) (20 min)

Surveys of AI Risks
1. [AI Risks that Could Lead to Catastrophe | CAIS](https://www.safe.ai/ai-risk) (25 min)
2. [Preventing an AI-Related Catastrophe - 80,000 Hours](https://80000hours.org/problem-profiles/artificial-intelligence/#top) (60 min)

Concrete Scenarios
1. [What Failure Looks Like by Paul Christiano](https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like) (20 min)
2. [Auto-GPT and AI Race Acceleration by The AI Beat](https://venturebeat.com/ai/as-ai-agents-like-auto-gpt-speed-up-generative-ai-race-we-all-need-to-buckle-up-the-ai-beat/) (10 min)
3. [The True Story of How GPT-2 Became Maximally Lewd](https://youtu.be/qV_rOlHjvvs?si=Y3li7yEXmQ-L7z0i) (14 min)


#### Learning Goals:
1. Understand the core arguments for existential risk from AI
2. Begin to form an idea of the different paths to reducing AI risk
3. Visualize how the techniques used to train AI directly contribute to potential bad outcomes




### Week 3: AI Safety -- Goals and Challenges


#### Core Content (~60 min):

1. [Paradigms of AI Alignment: Components and Enablers](https://www.youtube.com/watch?v=ogck1GCSP0E) (34 min)
2. [Avoiding Extreme Global Vulnerability as a Core AI Governance Problem](https://aisafetyfundamentals.com/blog/global-vulnerability/) (10 min)
3. [AI Safety Seems Hard to Measure](https://www.cold-takes.com/ai-safety-seems-hard-to-measure/) (16 min)


#### Optional Additional Content:

AI Safety Neglectedness
1. [Nobody's on the Ball on AI Alignment](https://www.forourposterity.com/nobodys-on-the-ball-on-agi-alignment/) (15 min)
2. [The Need for Work on Technical AI Alignment by Daniel Eth](https://aisafetyfundamentals.com/blog/alignment-introduction) (25 min)

What Could Go Wrong
1. [AGI Ruin: A List of Lethalities](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities) (20 min)
2. [Rogue AIs by the Center for AI Safety](https://www.aisafetybook.com/textbook/rogue-ai) (35 min)
3. [Racing through a minefield: the AI deployment problem](https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/) (18 min)

Paths to Success
1. [Paradigms of AI Alignment: Components and Enablers](https://youtu.be/ZeecOKBus3Q) (34 min)
2. [Managing Extreme AI Risks Amid Rapid Progress](https://arxiv.org/abs/2310.17688) (20 min)
3. [What is AI Alignment? – BlueDot Impact](https://aisafetyfundamentals.com/blog/what-is-ai-alignment/) (10 min)


#### Learning Goals:
1. Understand the term "AI alignment" -- what it means, and paths to achieving it
2. Understand the difficulties that arise when trying to align powerful AI models
3. Build a framework for the various factors that exascerbate AI risk, and how each of these could potentially be mitigated


## Part 2: Introduction to AI Governance


### Week 4: AI Policy Levers


#### Core Content (~60 min):


1. [The AI Triad and What It Means for National Security Strategy](https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Triad-Report.pdf) (45 min)
2. [Primer on Safety Standards and Regulations for Industrial-Scale AI Development](https://aisafetyfundamentals.com/blog/standards-and-regulations-primer) (15 min)


#### Optional Additional Content:


1. [Strengthening Resilience to AI Risk: A Guide for UK Policymakers](https://cetas.turing.ac.uk/sites/default/files/2023-08/cetas-cltr_ai_risk_briefing_paper.pdf) (30 min)
2. [The Policy Playbook: Building a Systems-Oriented Approach to Technology and National Security Policy](https://cset.georgetown.edu/wp-content/uploads/The-Policy-Playbook.pdf) (45 min)
3. [The Convergence of Artificial Intelligence and the Life Sciences: Safeguarding Technology](https://www.nti.org/wp-content/uploads/2023/10/NTIBIO_AI_FINAL.pdf) (8 min)
4. [Historical Case Studies of Technology Governance and International Agreements](https://www.aisafetyfundamentals.com/blog/historical-case-studies/) (30 min)


#### Learning Goals:
1. Understand the direct implications of the AI triad for policy
2. Learn about existing standards for AI
3. Gain historical context on the successes and failures of past technology governance


### Week 5: Existing Approaches -- Corporate Governance & Open vs. Closed Source


#### Core Content (~60 min):


1. [AI Index Report 2024, Chapter 7: Policy and Governance](https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024_Chapter_7.pdf) (20 min)
2. [Meta's Chief AI Scientist Yann LeCun talks about the future of artificial intelligence](https://youtu.be/Ah6nR8YAYF4?si=yHTADyt3csu7gE3c) (6 min)
3. [Open Sourcing Highly Capable Foundation Models](https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models) (34 min)


#### Optional Additional Content:

US AI Policy
1. [Recent U.S. Efforts on AI Policy](https://www.cisa.gov/ai/recent-efforts) (8 min)
2. [President Biden's Executive Order on AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) (10 min)

Principles and Recommendations
1. [The Bletchley Declaration](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023) (10 min)
2. [UNESCO’s Recommendation on the Ethics of AI](https://unesdoc.unesco.org/ark:/48223/pf0000385082) (20 min)
3. [OECD AI Principles](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449) (10 min)

Open vs. Closed Source
1. [A Pro-Innovation Approach to AI Regulation](https://www.gov.uk/government/consultations/ai-regulation-a-pro-innovation-approach-policy-proposals/outcome/a-pro-innovation-approach-to-ai-regulation-government-response#executive-summary) (30 min)
2. [The Case for Uncensored Models](https://erichartford.com/uncensored-models) (5 min)


#### Learning Goals:
1. Understand the term "corporate governance," and existing policies held by AI labs
2. Weigh the pros and cons of open-sourcing model weights
3. Understand the government's role in the regulation of AI companies


### Week 6: New Approaches -- Compute Governance & International Approaches


#### Core Content (~60 min):


1. [Computing Power and the Governance of AI](https://www.governance.ai/post/computing-power-and-the-governance-of-ai) (20 min)
2. [What Should be Internationalized in AI Governance?](https://oms-www.files.svdcdn.com/production/downloads/What%20should%20be%20internationalised%20in%20AI%20Governance-final.pdf?dm=1731486256) (40 min)


#### Optional Additional Content:

Compute Governance
1. [Choking Off China’s Access to the Future of AI](https://www.csis.org/analysis/choking-chinas-access-future-ai) (15 min)
2. [Computing Power and the Governance of AI](https://arxiv.org/abs/2402.08797) (45 min)
3. [Primer on AI Chips and AI Governance](https://aisafetyfundamentals.com/blog/primer-on-ai-chips) (20 min)

Institutions and Policies
1. [China’s AI Regulations and How They Get Made](https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117) (20 min)
2. [Driving U.S. Innovation in Artificial Intelligence: A Roadmap for AI Policy](https://www.politico.com/f/?id=0000018f-79a9-d62d-ab9f-f9af975d0000) (30 min)
3. [High-Level Summary of the AI Act](https://artificialintelligenceact.eu/high-level-summary/) (10 min)
4. [Vision Statement of the US AI Safety Institute](https://www.nist.gov/system/files/documents/2024/05/21/AISI-vision-21May2024.pdf) (15 min)
5. [International Institutions for Advanced AI](https://arxiv.org/abs/2307.04699) (20 min)

AI Control
5. [Model Evaluation for Extreme Risks by Toby Shevlane](https://arxiv.org/pdf/2305.15324.pdf) (35 min)
6. [Societal Adaptation to Advanced AI](https://drive.google.com/file/d/1k3uqK0dR9hVyG20-eBkR75_eYP2efolS/view?usp=sharing) (40 min)


#### Learning Goals:
1. Understand the term "compute governance," and why regulating compute is a promising path for mitigating AI risk
2. Survey existing international instiutions for AI, and proposals for new institutions
3. Gain context on the state of AI in China, the US's primary competitor in the field


### Week 7: Looking Ahead


#### Core Content (~60 min):


1. [Career Profile: AI Governance and Policy by 80000 Hours](https://80000hours.org/career-reviews/ai-policy-and-strategy/) (15 min)
2. [AI Governance Project Ideas – BlueDot Impact](https://aisafetyfundamentals.com/blog/ai-governance-project-ideas/) (10 min)
3. [Collection of AI Governance Research Ideas - Markus Anderlung](https://www.markusanderljung.com/blog/a-collection-of-ai-governance-research-ideas-2024#WhyWMDsResilience) (20 min)
4. [Advice for Undergraduates](https://emergingtechpolicy.org/pathways/undergraduate-advice/) (15 min)


#### Optional Additional Content:

Skills to Build
1. [10 skills you need to grow your public policy career](https://onlinecourses.bsg.ox.ac.uk/blog/public-policy-skills-you-need-to-grow-your-career/)
2. [Aptitudes for AI Governance Work](https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work)

Advice and Ideas
1. [Advice for Seeking Full-Time Roles](https://emergingtechpolicy.org/pathways/full-time-roles/) (8 min)
2. [12 Tentative Ideas for U.S. AI Policy by Muehlhauser](https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/) (5 min)
3. [So You Want to Be a Policy Entrepreneur? by Michael Mintrom](https://www.tandfonline.com/doi/full/10.1080/25741292.2019.1675989) (40 min)
4. [What's next in AI Governance](https://youtu.be/AbTXdXGyUPk?si=XXA6QJpn2uulRMj4) (58 min)

Career Resources
1. [Career Resources on US AI Policy](https://www.agisf.com/governance-blog/us-ai-policy-careers) (5 min)
2. [Career Resources on US AI Strategy Research](https://www.agisf.com/governance-blog/ai-strategy-careers) (12 min)
3. [AI Policy Resources](https://emergingtechpolicy.org/areas/ai-policy/)
4. [AI Safety Career Opportunities Job Board](https://jobs.80000hours.org/?refinementList%5Btags_area%5D%5B0%5D=AI%20safety%20%26%20policy&utm_source=aisf)


#### Learning Goals:
1. Understand what careers exist in the AI governance space, and the skills required for each
2. Browse proposals for AI governance and take note of the ones you may be interested in pursuing
3. Understand the resources available to you if you are interested in pursuing AI governance
