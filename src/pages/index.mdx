---
layout: ../layouts/SimpleLayout.astro
---

import GPT3 from "../components/GPT3";

<div className="flex flex-wrap sm:flex-row items-center">
<div className="sm:w-2/3 text-xl">
# We are AI Safety at UCLA

We believe that AI will radically change the world we live in.

Let's make it for the better.

<a href="//discord.gg/37TzSyrwmf" target="_blank" className="rounded-lg mb-4 sm:mb-0 not-prose bg-slate-900 inline-block p-4 text-slate-100">Join Discord</a>
</div>
<div className="w-full sm:w-1/3 sm:pl-10 align-middle h-fit">
<GPT3 client:only/>
</div>
</div>

## Why AI Safety?

AI systems have a potential to massively benefit humanity. However, the development of these systems
poses equally incredible risks. The risks posed are **existential** for the human species.

Ensuring any AI system's goals are aligned with ours
[is](https://openai.com/index/faulty-reward-functions/)
[a](https://www.lesswrong.com/w/inner-alignment)
[non-trivial](https://www.decisionproblem.com/paperclips/)
[task](https://en.wikipedia.org/wiki/Goodhart%27s_law).
Most notably, **we only get one try to get this right.**

## What we do

We think that the best way to make progress on the problem of AI safety is
getting more people to focus their careers on AI safety research, in fields
like mechanistic interpretability, adversarial robustness, or AI governance.

**All of our curriculum is available online.**

Click [here](/fellowships) for fellowships, and click [here](/upskilling-tracks) for the upskilling tracks.

If you'd like see some projects we've worked on in the past, click [here](/upskilling-tracks/projects).

## Resources

As one of the forefront AI clubs at UCLA, we adminisitrate the largest GPU server of any
UCLA club. Members get access to train models on our GPUs (NVIDIA 3090s). Check below to
see a live feed of our GPU utilization (updates every 10 minutes).

<a href="//stats.ais-ucla.org/"><img alt="GPU utilization, last week" src="//stats.ais-ucla.org/gpu1wk.png" class="mx-auto"/></a>

